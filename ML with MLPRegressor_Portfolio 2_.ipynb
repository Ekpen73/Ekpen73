{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution for choosing appropriate nodes for MLP Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas from python library for dataset-CSV file imoprts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('regression2(1).csv', names=['x1','x2','y'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.233919</td>\n",
       "      <td>-0.013329</td>\n",
       "      <td>9.361402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.900994</td>\n",
       "      <td>2.889343</td>\n",
       "      <td>47.613754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.968200</td>\n",
       "      <td>-4.977100</td>\n",
       "      <td>-138.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.285350</td>\n",
       "      <td>-2.511675</td>\n",
       "      <td>-23.345750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.327460</td>\n",
       "      <td>-0.121155</td>\n",
       "      <td>5.001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.706875</td>\n",
       "      <td>2.479325</td>\n",
       "      <td>42.488250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.989400</td>\n",
       "      <td>5.093000</td>\n",
       "      <td>142.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x1          x2           y\n",
       "count  500.000000  500.000000  500.000000\n",
       "mean     0.233919   -0.013329    9.361402\n",
       "std      2.900994    2.889343   47.613754\n",
       "min     -4.968200   -4.977100 -138.930000\n",
       "25%     -2.285350   -2.511675  -23.345750\n",
       "50%      0.327460   -0.121155    5.001250\n",
       "75%      2.706875    2.479325   42.488250\n",
       "max      4.989400    5.093000  142.150000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary python Libraries for creating the Multi-layer perceptron used in the MLPRegression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for training and testing\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an array of dependants and independents variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('regression2(1).csv', names=['x1','x2','y'])\n",
    "# creates vector of columns\n",
    "target_column = ['y']\n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "# get column from first and second index\n",
    "X = df.iloc[:,:2]\n",
    "# get columns from third column\n",
    "y = df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 2)\n",
      "(150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the features on the trainning data to allow for normalization as recommended by sklearn documentation\n",
    "#### https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_trainscaled=sc_X.fit_transform(X_train)\n",
    "X_testscaled=sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the MLP Regressor Model\n",
    "\n",
    "#### MLPRegressor trains iteratively, at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update  the parameters. It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting.  The model parameters used in this task is taken from the SKlearn documentation https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', hidden_layer_sizes=(50,), max_iter=1700,\n",
       "             random_state=1, solver='sgd')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp=MLPRegressor(activation='logistic', solver ='sgd', learning_rate='constant', hidden_layer_sizes=(50,), max_iter=1700, random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "# solvers 'lbfgs', 'adam'.\n",
    "#activation{‘identity’, ‘logistic’, ‘tanh’,\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization Error:\n",
    "### The generalization error produced in this result, using the above parameters in creating the MLP Regressor tend to be low compare to other parameters.  I have also provide two curves below to demonstrate the impact of the two activation function on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training : 0.76\n",
      "Accuracy testing : 0.72\n",
      "Loss :  279.35922246249146\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy training : {:.2f}'.format(mlp.score(X_train,y_train)))\n",
    "print('Accuracy testing : {:.2f}'.format(mlp.score(X_test,y_test)))\n",
    "print(\"Loss : \", mlp.loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Performance\n",
    "### The mean Absolute Error:\n",
    "#### The absolute error is the absolute value of the difference between the predicted value and the actual value,  It takes the average of all the error from every sample in a dataset and gives the output.  MAE tells us how big of an error we can expect from the prediction on average. the result in the error shows the prediction has 18.8 average error\n",
    "### The mean squared error: \n",
    "#### The metric square the errors in the predictions before calculating their mean and then taking the square root of the mean, it then arrive at a measure of the size of the error that gives more weight to the large but infrequent errors than the mean. it tend to provide a balance between overfitting and underfitting. The lower the value the better. In this task using the stated parameter in the mlp regressor as used above provides the understated value of 558.54 and in comparison to using other parameters, this gives a lower value.\n",
    "### The coefficient of determination:\n",
    "#### This metric gives an indication of how good a model fits a given dataset. The R squared value lies between 0 and 1 where 0 indicates that this model doesn't fit the given data and 1 indicates that the model fits perfectly to the dataset provided. The result of 0.757 or 0.76 shows that 76% of the data fits the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absollute Error: 18.834778731549623\n",
      "Mean Squared Error: 558.5376811351946\n",
      "Coefficient of Determination: 0.7568018501394526\n",
      "Loss :  279.35922246249146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "\n",
    "mae = metrics.mean_absolute_error(y_train, mlp.predict(X_train))\n",
    "mse = metrics.mean_squared_error(y_train, mlp.predict(X_train))\n",
    "rsq = metrics.r2_score(y_train, mlp.predict(X_train))\n",
    "\n",
    "print('Mean Absollute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Coefficient of Determination:', rsq)\n",
    "print(\"Loss : \", mlp.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absollute Error: 20.067259345982237\n",
      "Mean Squared Error: 603.2929394883461\n",
      "Coefficient of Determination: 0.723376289449297\n"
     ]
    }
   ],
   "source": [
    "mae = metrics.mean_absolute_error(y_test, mlp.predict(X_test))\n",
    "mse = metrics.mean_squared_error(y_test, mlp.predict(X_test))\n",
    "rsq = metrics.r2_score(y_test, mlp.predict(X_test))\n",
    "\n",
    "print('Mean Absollute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Coefficient of Determination:', rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions of trained data with accuracy level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy training : {:.3f}'.format(mlp.score(X_train,y_train)))\n",
    "print('Accuracy testing : {:.3f}'.format(mlp.score(X_test,y_test)))\n",
    "y_train_predicted = mlp.predict(X_train)\n",
    "print(y_train_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the 'loss_curve_'  protery on model to see how well the model is learning over the iterations.\n",
    "### Using logistic activation function, with 50 nodes and 1700 epochs(see more explantion above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(mlp.loss_curve_).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For comparison purpose of the impact of different activation function\n",
    "### Using tanh activation function.\n",
    "#### The below curve is met to compare the Loss curve given different activation function, here tanh activation function was used, tanh appears to reduced the generalization error more, given the same nodes and epochs. This is depicted in the curve been flattened.  Also the Accuracy training and testing slightly improved compare to using logistic activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training : 0.77\n",
      "Accuracy testing : 0.74\n",
      "Loss :  269.4168739458424\n",
      "Mean Absollute Error: 20.067259345982237\n",
      "Mean Squared Error: 603.2929394883461\n",
      "Coefficient of Determination: 0.723376289449297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp=MLPRegressor(activation='tanh', solver ='sgd', learning_rate='constant', hidden_layer_sizes=(50,), max_iter=1700, random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "# solvers 'lbfgs', 'adam'.\n",
    "#activation{‘identity’, ‘logistic’, ‘tanh’,\n",
    "mlp\n",
    "print('Accuracy training : {:.2f}'.format(mlp.score(X_train,y_train)))\n",
    "print('Accuracy testing : {:.2f}'.format(mlp.score(X_test,y_test)))\n",
    "print(\"Loss : \", mlp.loss_)\n",
    "print('Mean Absollute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Coefficient of Determination:', rsq)\n",
    "pd.DataFrame(mlp.loss_curve_).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Methodology and justification of Choice of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the modules used in modelling the MLPRegressor was imported from python library. I started by importing the data set. This data was then divided into two set, 70% for training and 30% for testing. Thereafter the Dataset features were scaled as recommended by Sklearn API documentation. \n",
    "The MLPRegressor was created using the default parameters from the Sklearn documentation. \n",
    "\n",
    "Solver{‘lbfgs’, ‘sgd’, ‘adam’}.\n",
    "\n",
    "In training the model I used all the solvers  above in the documentation  to observe which one will give the best result.\n",
    "The solver which updates weights values that minimize the loss function in batches among other solver was the “stochastic gradient descent(Sgd).\n",
    "The “Sgd”  with maximum iteration(epochs) of 1800, optimises the  loss function( seen  graph above).  Sgd when compared to other solver appears to be faster to converge in comparison to other solvers.  In search of the number of nodes after using various numbers, the following gave the same and a better result: \n",
    "\n",
    "50 node at an epochs of 1700 or\n",
    "100 nodes at an epoch of 1800\n",
    "\n",
    "The generalization error (see graph above) was the more reduced at using 50 nodes with epochs of 1700.\n",
    "\n",
    "Activation {‘identity’, ‘logistic’, ‘tanh’},\n",
    "\n",
    "Activation function for the hidden layer used in this task were logistics and tanh, the two was used for comparison purpose and produced a better comparable result to other activation function. Tanh appears to reduce further the generalization error with slightly higher accuracy(see graph above).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
